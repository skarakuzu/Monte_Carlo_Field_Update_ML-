{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7e2e9e3-0e1f-4bab-816f-e838e1f5b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#from realistic_python_call import ffi\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.argv = ['pdm']\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class MyFcClass:\n",
    "    def __init__(self):\n",
    "        print (\"hello in constructor of MyFcClass\")\n",
    "        self.Ntrain = 130000\n",
    "        self.Nvalid = 20000\n",
    "        self.size = 28\n",
    "        self.nclass = 1\n",
    "        self.h1 = 15\n",
    "        self.h2 = 10\n",
    "        self.batch_size = 1000\n",
    "        self.epochs = 200\n",
    "        print (\"num epoch: \",self.epochs)\n",
    "        self.display_freq = 1\n",
    "        self.learning_rate = 0.0025\n",
    "        self.x_train = np.zeros((self.Ntrain,self.size),dtype = 'float')\n",
    "        self.y_train = np.zeros((self.Ntrain,self.nclass),dtype = 'float')\n",
    "        self.x_valid = np.zeros((self.Nvalid,self.size),dtype = 'float')\n",
    "        self.y_valid = np.zeros((self.Nvalid,self.nclass),dtype = 'float')\n",
    "    \n",
    "        self.output = self.create_model() \n",
    "    \n",
    "        self.loss = 'logcosh' # 'mean_squared_error'\n",
    "\n",
    "        self.optim = tf.keras.optimizers.Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        \n",
    "    def create_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(20, activation='softplus'))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "        \n",
    "        return model\n",
    "   \n",
    "    def load_data(self):\n",
    "        print('now loading data')\n",
    "        data_dqmc = np.loadtxt(\"DataSingleOut_short.txt\", usecols = range(0,33))\n",
    "        self.x_train = data_dqmc[0:self.Ntrain,4:32]\n",
    "        self.y_train = data_dqmc[0:self.Ntrain,2:3]\n",
    "\n",
    "        self.x_valid = data_dqmc[self.Ntrain:self.Ntrain+self.Nvalid,4:32]\n",
    "        self.y_valid = data_dqmc[self.Ntrain:self.Ntrain+self.Nvalid,2:3]\n",
    "\n",
    "\n",
    "        print('x_train:\\t{}'.format(self.x_train.shape))\n",
    "        print('y_train:\\t{}'.format(self.y_train.shape))\n",
    "        print('x_valid:\\t{}'.format(self.x_valid.shape))\n",
    "        print('y_valid:\\t{}'.format(self.y_valid.shape))\n",
    "    \n",
    "    def reshape_data(self):\n",
    "        w, h = self.size, 1\n",
    "        self.x_train = self.x_train.reshape(self.x_train.shape[0], w, h, 1)\n",
    "        self.x_test = self.x_test.reshape(self.x_test.shape[0], w, h, 1)\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.output.save('fcmodel.h5')\n",
    "      \n",
    "    def restore_model(self):\n",
    "        self.output = tf.keras.models.load_model('fcmodel.h5')  \n",
    "        \n",
    "    def train_now(self):\n",
    "        print('compiling now')\n",
    "        self.output.compile(loss=self.loss,\n",
    "                 optimizer=self.optim,\n",
    "                 metrics=['accuracy'])\n",
    "        print('training now')\n",
    "        self.output.fit(self.x_train,\n",
    "             self.y_train,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs)    \n",
    "        \n",
    "        \n",
    "    def predict_now(self):\n",
    "        p = self.output.predict(self.x_valid)\n",
    "        plt.plot(p,self.y_valid,'o')\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34e19802-3070-4f63-9823-1cd872cb548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in constructor of MyFcClass\n",
      "num epoch:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    my_obj = MyFcClass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "930181e6-f152-4c42-b319-9102ce8c7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading data\n",
      "x_train:\t(130000, 28)\n",
      "y_train:\t(130000, 1)\n",
      "x_valid:\t(20000, 28)\n",
      "y_valid:\t(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "    my_obj.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de3301-759b-4211-899d-0d9a4583ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling now\n",
      "training now\n",
      "Epoch 1/200\n",
      "130/130 [==============================] - 1s 3ms/step - loss: 1.5686 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 1.5326 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 1.4938 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 1.3799 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 1.1133 - accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.7842 - accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "  1/130 [..............................] - ETA: 0s - loss: 0.0017 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "    my_obj.train_now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdf1bb9c-f7e7-4012-a607-90273d4f4dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    my_obj.predict_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d669e0-5c2c-4329-80c7-5d5bcb8f7801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
