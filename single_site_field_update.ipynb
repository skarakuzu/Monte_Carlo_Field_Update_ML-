{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7e2e9e3-0e1f-4bab-816f-e838e1f5b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#from realistic_python_call import ffi\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.argv = ['pdm']\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class MyFcClass:\n",
    "    def __init__(self):\n",
    "        print (\"hello in constructor of MyFcClass\")\n",
    "        self.Ntrain = 4000000\n",
    "        self.Nvalid = 200000\n",
    "        self.size = 28\n",
    "        self.nclass = 1\n",
    "        self.h1 = 15\n",
    "        self.h2 = 10\n",
    "        self.batch_size = 1000\n",
    "        self.epochs = 100\n",
    "        print (\"num epoch: \",self.epochs)\n",
    "        self.display_freq = 1\n",
    "        self.learning_rate = 0.001\n",
    "        self.x_train = np.zeros((self.Ntrain,self.size),dtype = 'float')\n",
    "        self.y_train = np.zeros((self.Ntrain,self.nclass),dtype = 'float')\n",
    "        self.x_valid = np.zeros((self.Nvalid,self.size),dtype = 'float')\n",
    "        self.y_valid = np.zeros((self.Nvalid,self.nclass),dtype = 'float')\n",
    "    \n",
    "        self.output = self.create_model() \n",
    "    \n",
    "        self.loss = 'logcosh' # 'mean_squared_error'\n",
    "\n",
    "        self.optim = tf.keras.optimizers.Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        \n",
    "    def create_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(20, activation='softplus'))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "        \n",
    "        return model\n",
    "   \n",
    "    def load_data(self):\n",
    "        print('now loading data')\n",
    "        data_dqmc = np.loadtxt(\"DataSingleOut.txt\", usecols = range(0,33))\n",
    "        self.x_train = data_dqmc[0:self.Ntrain,4:32]\n",
    "        self.y_train = data_dqmc[0:self.Ntrain,2:3]\n",
    "\n",
    "        self.x_valid = data_dqmc[self.Ntrain:self.Ntrain+self.Nvalid,4:32]\n",
    "        self.y_valid = data_dqmc[self.Ntrain:self.Ntrain+self.Nvalid,2:3]\n",
    "\n",
    "\n",
    "        print('x_train:\\t{}'.format(self.x_train.shape))\n",
    "        print('y_train:\\t{}'.format(self.y_train.shape))\n",
    "        print('x_valid:\\t{}'.format(self.x_valid.shape))\n",
    "        print('y_valid:\\t{}'.format(self.y_valid.shape))\n",
    "    \n",
    "    def reshape_data(self):\n",
    "        w, h = self.size, 1\n",
    "        self.x_train = self.x_train.reshape(self.x_train.shape[0], w, h, 1)\n",
    "        self.x_test = self.x_test.reshape(self.x_test.shape[0], w, h, 1)\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.output.save('fcmodel.h5')\n",
    "      \n",
    "    def restore_model(self):\n",
    "        self.output = tf.keras.models.load_model('fcmodel.h5')  \n",
    "        \n",
    "    def train_now(self):\n",
    "        print('compiling now')\n",
    "        self.output.compile(loss=self.loss,\n",
    "                 optimizer=self.optim,\n",
    "                 metrics=['accuracy'])\n",
    "        print('training now')\n",
    "        self.output.fit(self.x_train,\n",
    "             self.y_train,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs)    \n",
    "        \n",
    "        \n",
    "    def predict_now(self):\n",
    "        p = self.output.predict(self.x_valid)\n",
    "        plt.plot(p,self.y_valid,'o')\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34e19802-3070-4f63-9823-1cd872cb548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in constructor of MyFcClass\n",
      "num epoch:  100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    my_obj = MyFcClass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "930181e6-f152-4c42-b319-9102ce8c7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading data\n",
      "x_train:\t(4000000, 28)\n",
      "y_train:\t(4000000, 1)\n",
      "x_valid:\t(200000, 28)\n",
      "y_valid:\t(200000, 1)\n"
     ]
    }
   ],
   "source": [
    "    my_obj.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48de3301-759b-4211-899d-0d9a4583ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling now\n",
      "training now\n",
      "Epoch 1/100\n",
      "4000/4000 [==============================] - 4s 905us/step - loss: 0.7432 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 4s 912us/step - loss: 0.0579 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 4s 915us/step - loss: 0.0203 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 4s 911us/step - loss: 0.0088 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 4s 915us/step - loss: 0.0047 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 4s 913us/step - loss: 0.0026 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 4s 908us/step - loss: 0.0016 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 4s 911us/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 4s 912us/step - loss: 0.0010 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 4s 911us/step - loss: 9.1264e-04 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 4s 915us/step - loss: 8.3055e-04 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 4s 925us/step - loss: 7.6417e-04 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 4s 910us/step - loss: 7.1069e-04 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 4s 918us/step - loss: 6.6412e-04 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 4s 902us/step - loss: 6.2930e-04 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 4s 906us/step - loss: 5.8947e-04 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 4s 914us/step - loss: 5.5886e-04 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 4s 908us/step - loss: 5.3492e-04 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 4s 906us/step - loss: 5.0803e-04 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 4s 909us/step - loss: 4.7957e-04 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 4s 903us/step - loss: 4.6319e-04 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 4s 902us/step - loss: 4.4034e-04 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 4s 900us/step - loss: 4.2290e-04 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 4s 902us/step - loss: 4.0593e-04 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 3.8745e-04 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 4s 899us/step - loss: 3.7823e-04 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 4s 904us/step - loss: 3.5691e-04 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 3.4257e-04 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 3.3137e-04 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 4s 890us/step - loss: 3.1707e-04 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 4s 892us/step - loss: 3.0474e-04 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 4s 895us/step - loss: 2.9175e-04 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 4s 901us/step - loss: 2.8322e-04 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 4s 901us/step - loss: 2.7175e-04 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 4s 902us/step - loss: 2.6455e-04 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 4s 889us/step - loss: 2.5803e-04 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 3s 874us/step - loss: 2.4732e-04 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 4s 886us/step - loss: 2.4165e-04 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 4s 881us/step - loss: 2.3740e-04 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 4s 902us/step - loss: 2.2815e-04 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 4s 888us/step - loss: 2.2541e-04 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 4s 904us/step - loss: 2.1896e-04 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 4s 889us/step - loss: 2.1561e-04 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 4s 886us/step - loss: 2.1148e-04 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "4000/4000 [==============================] - 4s 886us/step - loss: 2.0745e-04 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 4s 895us/step - loss: 2.0633e-04 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 2.0131e-04 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 4s 887us/step - loss: 2.0069e-04 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 4s 888us/step - loss: 1.9874e-04 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 4s 887us/step - loss: 1.9657e-04 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 4s 885us/step - loss: 1.9131e-04 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 4s 900us/step - loss: 1.9233e-04 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 4s 909us/step - loss: 1.8935e-04 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 4s 889us/step - loss: 1.8904e-04 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 1.8666e-04 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 1.8650e-04 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 1.8281e-04 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 1.8302e-04 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 1.7957e-04 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 4s 888us/step - loss: 1.8170e-04 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 4s 892us/step - loss: 1.7717e-04 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 1.7803e-04 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 1.7628e-04 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 4s 890us/step - loss: 1.7363e-04 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 1.7387e-04 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 4s 897us/step - loss: 1.7230e-04 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 4s 898us/step - loss: 1.7112e-04 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 4s 892us/step - loss: 1.7079e-04 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 1.7036e-04 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 4s 892us/step - loss: 1.6815e-04 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 4s 895us/step - loss: 1.6806e-04 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 4s 898us/step - loss: 1.6592e-04 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 4s 901us/step - loss: 1.6642e-04 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 4s 894us/step - loss: 1.6473e-04 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 4s 897us/step - loss: 1.6521e-04 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 4s 899us/step - loss: 1.6260e-04 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 4s 895us/step - loss: 1.6252e-04 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 4s 892us/step - loss: 1.6236e-04 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 4s 897us/step - loss: 1.6003e-04 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 4s 894us/step - loss: 1.5956e-04 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "4000/4000 [==============================] - 4s 897us/step - loss: 1.6121e-04 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 4s 898us/step - loss: 1.5644e-04 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 4s 897us/step - loss: 1.5792e-04 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 4s 899us/step - loss: 1.5682e-04 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 4s 892us/step - loss: 1.5716e-04 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 4s 899us/step - loss: 1.5502e-04 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "4000/4000 [==============================] - 4s 907us/step - loss: 1.5550e-04 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 4s 895us/step - loss: 1.5279e-04 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "4000/4000 [==============================] - 4s 899us/step - loss: 1.5338e-04 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 3s 813us/step - loss: 1.5207e-04 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 3s 798us/step - loss: 1.5144e-04 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 3s 809us/step - loss: 1.5194e-04 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "4000/4000 [==============================] - 3s 820us/step - loss: 1.5050e-04 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 3s 796us/step - loss: 1.5075e-04 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 3s 801us/step - loss: 1.4800e-04 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 3s 809us/step - loss: 1.4813e-04 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 3s 795us/step - loss: 1.4900e-04 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 3s 822us/step - loss: 1.4685e-04 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 3s 832us/step - loss: 1.4828e-04 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 3s 841us/step - loss: 1.4530e-04 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "    my_obj.train_now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdf1bb9c-f7e7-4012-a607-90273d4f4dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    my_obj.predict_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d669e0-5c2c-4329-80c7-5d5bcb8f7801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
